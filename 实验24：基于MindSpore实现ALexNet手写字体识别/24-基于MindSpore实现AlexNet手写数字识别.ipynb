{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 基于MindSpore实现AlexNet手写字体识别\n",
    "\n",
    "本实验主要介绍使用华为的深度学习框架MindSpore实现的AlexNet模型，用于手写字体的图像分类任务，使用的数据集为MNIST手写数字数据集。该实验旨在展示如何使用MindSpore框架构建深度学习模型，并在手写数字分类任务中进行训练和测试。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.实验目的\n",
    "\n",
    "- 掌握如何使用MindSpore框架构建深度学习模型。\n",
    "\n",
    "- 掌握如何在手写数字分类任务中使用MindSpore进行数据处理、模型构建、训练和评估。\n",
    "\n",
    "- 了解AlexNet模型的基本结构和工作原理。\n",
    "\n",
    "- 通过手写数字识别任务掌握深度学习在计算机视觉中的应用。\n",
    "\n",
    "- 掌握如何使用深度学习模型解决实际问题。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.AlexNet模型原理介绍\n",
    "\n",
    "[AlexNet](http://www.cs.toronto.edu/~hinton/absps/imagenet.pdf)是一种深度卷积神经网络模型，是由Alex Krizhevsky、Ilya Sutskever和Geoffrey Hinton在2012年ImageNet大规模视觉识别竞赛（ImageNet Large Scale Visual Recognition Challenge, ILSVRC）中提出并夺得冠军的。AlexNet模型的主要结构包括5个卷积层和3个全连接层，其中，前5个卷积层之间以及最后2个全连接层之间使用了ReLU激活函数，而最后一个全连接层使用了softmax激活函数。\n",
    "\n",
    "![jupyter](./Figures/Fig002.png)\n",
    "\n",
    "[AlexNet](http://www.cs.toronto.edu/~hinton/absps/imagenet.pdf)的卷积层采用了较大的卷积核（11x11、5x5），较大的步幅（4、2），以及较多的卷积通道（96、256），这样的设计使得模型具有更强的表征能力和更高的分类准确度。同时，在模型训练时，[AlexNet](http://www.cs.toronto.edu/~hinton/absps/imagenet.pdf)采用了数据增强和dropout等技术，以避免模型出现过拟合现象，提高模型的泛化能力。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.实验环境\n",
    "\n",
    "在动手进行实践之前，需要注意以下几点：\n",
    "* 确保实验环境正确安装，包括安装MindSpore。安装过程：首先登录[MindSpore官网安装页面](https://www.mindspore.cn/install)，根据安装指南下载安装包及查询相关文档。同时，官网环境安装也可以按下表说明找到对应环境搭建文档链接，根据环境搭建手册配置对应的实验环境。\n",
    "* 推荐使用交互式的计算环境Jupyter Notebook，其交互性强，易于可视化，适合频繁修改的数据分析实验环境。\n",
    "* 实验也可以在华为云一站式的AI开发平台ModelArts上完成。\n",
    "* 推荐实验环境：MindSpore版本=MindSpore 2.4；Python环境=3.11。\n",
    "\n",
    "\n",
    "|  硬件平台 |  操作系统  |          软件环境           | 开发环境 | 环境搭建链接 |\n",
    "| :-----:| :----: |:-----------------------:|:----:   |:----:   |\n",
    "| CPU | Windows-x64 | MindSpore2.4 Python3.11 | JupyterNotebook |[MindSpore环境搭建实验手册第二章2.1节和第三章3.1节](./MindSpore环境搭建实验手册.docx)|\n",
    "| GPU |Linux-x86_64| MindSpore2.4 Python3.11 | JupyterNotebook |[MindSpore环境搭建实验手册第二章2.2节和第三章3.1节](./MindSpore环境搭建实验手册.docx)|\n",
    "| Ascend 910  | Linux-x86_64| MindSpore2.4 Python3.11 | JupyterNotebook |[MindSpore环境搭建实验手册第四章](./MindSpore环境搭建实验手册.docx)|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.数据处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1数据准备\n",
    "\n",
    "MNIST数据集是机器学习中常用的数据集之一，它包含了70,000张手写数字图片，每张图片都是28x28像素大小的灰度图像，数字从0到9。该数据集由美国国家标准与技术研究所（NIST）于1999年创建，而后由Yann LeCun等人进行改进和维护，因此被称为MNIST（Modified NIST）数据集。\n",
    "\n",
    "MNIST数据集主要用于图像识别领域的研究，特别是用于机器学习算法的测试和比较。由于它的简单性和易于使用，MNIST已经成为机器学习社区中的标准数据集之一。\n",
    "\n",
    "以下是几个示例图像：\n",
    "\n",
    "![jupyter](./Figures/Fig001.png)\n",
    "\n",
    "每个图像都被转换成784个数字的一维向量（28×28=784）。这些数字表示像素的灰度值，值的范围从0（黑色）到255（白色）。为了将这些向量转换成有意义的输出，通常使用分类算法，例如支持向量机（SVM）或神经网络。分类算法的目标是将每个图像正确地标记为它所代表的数字。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2数据加载\n",
    "\n",
    "MindSpore提供了MNIST数据集并将其划分为训练集和测试集，我们只需下载载入即可。\n",
    "我们可以通过MnistDataset函数载入下载好的数据集，并且get_col_names()提供了查看数据集中所有列名称的功能。\n",
    "载入完成数据后，我们需要对数据集进行预处理，我们通过datapipe()函数实现对图片的预处理。\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T12:38:49.793261Z",
     "start_time": "2025-01-13T12:38:47.615874Z"
    }
   },
   "source": [
    "import mindspore \n",
    "from mindspore import nn as nn\n",
    "from mindspore.dataset import vision, transforms\n",
    "from mindspore.dataset import MnistDataset\n",
    "\n",
    "\n",
    "#下载数据集\n",
    "from download import download    \n",
    "\n",
    "url = \"https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/\" \\\n",
    "      \"notebook/datasets/MNIST_Data.zip\"\n",
    "path = download(url, \"./\", kind=\"zip\", replace=True)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/notebook/datasets/MNIST_Data.zip (10.3 MB)\n",
      "\n",
      "file_sizes: 100%|██████████████████████████| 10.8M/10.8M [00:00<00:00, 31.9MB/s]\n",
      "Extracting zip file...\n",
      "Successfully downloaded / unzipped to ./\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T12:38:52.160336Z",
     "start_time": "2025-01-13T12:38:52.153352Z"
    }
   },
   "source": [
    "# 载入数据集\n",
    "train_dataset = MnistDataset('MNIST_Data/train')\n",
    "test_dataset = MnistDataset('MNIST_Data/test')\n",
    "\n",
    "# 获取数据集中所有列的名称\n",
    "train_dataset.get_col_names() "
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['image', 'label']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T12:38:55.598293Z",
     "start_time": "2025-01-13T12:38:55.593441Z"
    }
   },
   "source": [
    "\n",
    "# datapipe完成映射图像变换和将大规模数据集分割成多个小批次的数据集\n",
    "def datapipe(dataset, batch_size):\n",
    "    image_transforms = [\n",
    "        vision.Rescale(1.0 / 255.0, 0),\n",
    "        vision.Resize((32, 32)),\n",
    "        vision.HWC2CHW()\n",
    "        \n",
    "    ]\n",
    "    label_transform = transforms.TypeCast(mindspore.int32)\n",
    "\n",
    "    dataset = dataset.map(image_transforms, 'image')\n",
    "    dataset = dataset.map(label_transform, 'label')\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    return dataset\n",
    "\n",
    "\n",
    "# 数据集预处理\n",
    "train_dataset = datapipe(train_dataset, 16)\n",
    "test_dataset = datapipe(test_dataset, 16)"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T12:38:58.259238Z",
     "start_time": "2025-01-13T12:38:58.207744Z"
    }
   },
   "source": [
    "# 结果展示 每个image包含16张图片，每张图片是单通道，高32像素，宽32像素\n",
    "for image, label in test_dataset.create_tuple_iterator():\n",
    "    print(f\"Shape of image [N, C, H, W]: {image.shape} {image.dtype}\")\n",
    "    print(f\"Shape of label: {label.shape} {label.dtype}\")\n",
    "    break\n",
    "\n",
    "for data in test_dataset.create_dict_iterator():\n",
    "    print(f\"Shape of image [N, C, H, W]: {data['image'].shape} {data['image'].dtype}\")\n",
    "    print(f\"Shape of label: {data['label'].shape} {data['label'].dtype}\")\n",
    "    break\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of image [N, C, H, W]: (16, 1, 32, 32) Float32\n",
      "Shape of label: (16,) Int32\n",
      "Shape of image [N, C, H, W]: (16, 1, 32, 32) Float32\n",
      "Shape of label: (16,) Int32\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.模型构建\n",
    "\n",
    "构建一个减少卷积层的精简版AlexNet：第一层为conv1，采用relu激活函数，第二层为最大池化层，第三层为conv2，采用relu激活函数，第四层为最大池化层，第五层为全连接层，第六层为全连接层，第七层为全连接层。使用交叉熵损失函数，和Adam优化器。"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T12:39:02.044565Z",
     "start_time": "2025-01-13T12:39:02.031749Z"
    }
   },
   "source": [
    "'''\n",
    "AlexNet的原始输入图片大小为224*224\n",
    "Mnist数据集中图片大小为28*28\n",
    "所以需要对网络进行精简，减少两层卷积层。\n",
    "'''\n",
    "\n",
    "class AlexNet(nn.Cell):\n",
    "    def __init__(self, num_class=10, num_channel=1):\n",
    "        super(AlexNet, self).__init__()\n",
    "        # 卷积层，输入的通道数为num_channel，输出的通道数为6，卷积核大小为5*5\n",
    "        self.conv1 = nn.Conv2d(num_channel, 6, 5, pad_mode='valid')\n",
    "        # 卷积层，输入的通道数为6，输出的通道数为16，卷积核大小为5*5\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5, pad_mode='valid')\n",
    "        # 全连接层，输入个数为16*5*5，输出个数为120\n",
    "        self.fc1 = nn.Dense(16 * 5 * 5, 120)\n",
    "        # 全连接层，输入个数为120，输出个数为84\n",
    "        self.fc2 = nn.Dense(120, 84)\n",
    "        # 全连接层，输入个数为84，分类的个数为num_class\n",
    "        self.fc3 = nn.Dense(84, num_class)\n",
    "        # ReLU激活函数\n",
    "        self.relu = nn.ReLU()\n",
    "        # 池化层\n",
    "        self.max_pool2d = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        # 多维数组展平为一维数组\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "    def construct(self, x):\n",
    "        # 使用定义好的运算构建前向网络\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.max_pool2d(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.max_pool2d(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "model = AlexNet()"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T12:39:04.210555Z",
     "start_time": "2025-01-13T12:39:04.199422Z"
    }
   },
   "source": [
    "# 损失函数、优化器\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = nn.Adam(params=model.trainable_params())"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.训练模型\n",
    "\n",
    "此部分分为两个部分，训练和测试。测试部分不需要计算梯度通过model.set_train(False)实现。"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T12:39:08.054209Z",
     "start_time": "2025-01-13T12:39:08.048454Z"
    }
   },
   "source": [
    "def train(model, dataset, loss_fn, optimizer):\n",
    "    # 定义前向传播\n",
    "    def forward_fn(data, label):\n",
    "        logits = model(data)\n",
    "        loss = loss_fn(logits, label)\n",
    "        return loss, logits\n",
    "\n",
    "    # 获取梯度\n",
    "    grad_fn = mindspore.value_and_grad(forward_fn, None, optimizer.parameters, has_aux=True)\n",
    "\n",
    "    # 获取每个batch损失\n",
    "    def train_step(data, label):\n",
    "        (loss, _), grads = grad_fn(data, label)\n",
    "        optimizer(grads)\n",
    "        return loss\n",
    "\n",
    "    size = dataset.get_dataset_size()\n",
    "    model.set_train()\n",
    "    for batch, (data, label) in enumerate(dataset.create_tuple_iterator()):\n",
    "        loss = train_step(data, label)\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.asnumpy(), batch\n",
    "            print(f\"loss: {loss:>7f}  [{current:>3d}/{size:>3d}]\")\n",
    "\n",
    "\n",
    "def test(model, dataset, loss_fn):\n",
    "    num_batches = dataset.get_dataset_size()\n",
    "    model.set_train(False)\n",
    "    total, test_loss, correct = 0, 0, 0\n",
    "    for data, label in dataset.create_tuple_iterator():\n",
    "        pred = model(data)\n",
    "        total += len(data)\n",
    "        test_loss += loss_fn(pred, label).asnumpy()\n",
    "        correct += (pred.argmax(1) == label).asnumpy().sum()\n",
    "    test_loss /= num_batches\n",
    "    correct /= total\n",
    "    print(f\"Test: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T12:42:05.800021Z",
     "start_time": "2025-01-13T12:39:22.480654Z"
    }
   },
   "source": [
    "#训练3个周期\n",
    "epochs = 3\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(model, train_dataset, loss_fn, optimizer)\n",
    "    #每个周期训练完的模型在测试集上验证\n",
    "    test(model, test_dataset, loss_fn)\n",
    "print(\"Done!\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.308531  [  0/3750]\n",
      "loss: 0.696949  [100/3750]\n",
      "loss: 0.527091  [200/3750]\n",
      "loss: 0.148770  [300/3750]\n",
      "loss: 0.069595  [400/3750]\n",
      "loss: 0.044726  [500/3750]\n",
      "loss: 0.010204  [600/3750]\n",
      "loss: 0.245963  [700/3750]\n",
      "loss: 0.106098  [800/3750]\n",
      "loss: 0.047226  [900/3750]\n",
      "loss: 0.066341  [1000/3750]\n",
      "loss: 0.117556  [1100/3750]\n",
      "loss: 0.156105  [1200/3750]\n",
      "loss: 0.029339  [1300/3750]\n",
      "loss: 0.171240  [1400/3750]\n",
      "loss: 0.009431  [1500/3750]\n",
      "loss: 0.168849  [1600/3750]\n",
      "loss: 0.030581  [1700/3750]\n",
      "loss: 0.040762  [1800/3750]\n",
      "loss: 0.081207  [1900/3750]\n",
      "loss: 0.074026  [2000/3750]\n",
      "loss: 0.288456  [2100/3750]\n",
      "loss: 0.377680  [2200/3750]\n",
      "loss: 0.009328  [2300/3750]\n",
      "loss: 0.358196  [2400/3750]\n",
      "loss: 0.022618  [2500/3750]\n",
      "loss: 0.004836  [2600/3750]\n",
      "loss: 0.160606  [2700/3750]\n",
      "loss: 0.129163  [2800/3750]\n",
      "loss: 0.446368  [2900/3750]\n",
      "loss: 0.064398  [3000/3750]\n",
      "loss: 0.020420  [3100/3750]\n",
      "loss: 0.047853  [3200/3750]\n",
      "loss: 0.035052  [3300/3750]\n",
      "loss: 0.060732  [3400/3750]\n",
      "loss: 0.014015  [3500/3750]\n",
      "loss: 0.091287  [3600/3750]\n",
      "loss: 0.256137  [3700/3750]\n",
      "Test: \n",
      " Accuracy: 97.8%, Avg loss: 0.072900 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.599872  [  0/3750]\n",
      "loss: 0.040320  [100/3750]\n",
      "loss: 0.012453  [200/3750]\n",
      "loss: 0.007555  [300/3750]\n",
      "loss: 0.017567  [400/3750]\n",
      "loss: 0.173997  [500/3750]\n",
      "loss: 0.144857  [600/3750]\n",
      "loss: 0.034986  [700/3750]\n",
      "loss: 0.015080  [800/3750]\n",
      "loss: 0.002232  [900/3750]\n",
      "loss: 0.006640  [1000/3750]\n",
      "loss: 0.011871  [1100/3750]\n",
      "loss: 0.009244  [1200/3750]\n",
      "loss: 0.003374  [1300/3750]\n",
      "loss: 0.005119  [1400/3750]\n",
      "loss: 0.022048  [1500/3750]\n",
      "loss: 0.016815  [1600/3750]\n",
      "loss: 0.001743  [1700/3750]\n",
      "loss: 0.188978  [1800/3750]\n",
      "loss: 0.265651  [1900/3750]\n",
      "loss: 0.037936  [2000/3750]\n",
      "loss: 0.679969  [2100/3750]\n",
      "loss: 0.078583  [2200/3750]\n",
      "loss: 0.020878  [2300/3750]\n",
      "loss: 0.261517  [2400/3750]\n",
      "loss: 0.014287  [2500/3750]\n",
      "loss: 0.006282  [2600/3750]\n",
      "loss: 0.006078  [2700/3750]\n",
      "loss: 0.001989  [2800/3750]\n",
      "loss: 0.006972  [2900/3750]\n",
      "loss: 0.019046  [3000/3750]\n",
      "loss: 0.002046  [3100/3750]\n",
      "loss: 0.005482  [3200/3750]\n",
      "loss: 0.016325  [3300/3750]\n",
      "loss: 0.021263  [3400/3750]\n",
      "loss: 0.010412  [3500/3750]\n",
      "loss: 0.010627  [3600/3750]\n",
      "loss: 0.017693  [3700/3750]\n",
      "Test: \n",
      " Accuracy: 98.6%, Avg loss: 0.047652 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.013273  [  0/3750]\n",
      "loss: 0.001074  [100/3750]\n",
      "loss: 0.019784  [200/3750]\n",
      "loss: 0.027282  [300/3750]\n",
      "loss: 0.014655  [400/3750]\n",
      "loss: 0.143204  [500/3750]\n",
      "loss: 0.022588  [600/3750]\n",
      "loss: 0.005353  [700/3750]\n",
      "loss: 0.001837  [800/3750]\n",
      "loss: 0.002967  [900/3750]\n",
      "loss: 0.001101  [1000/3750]\n",
      "loss: 0.009740  [1100/3750]\n",
      "loss: 0.001061  [1200/3750]\n",
      "loss: 0.045194  [1300/3750]\n",
      "loss: 0.006869  [1400/3750]\n",
      "loss: 0.004900  [1500/3750]\n",
      "loss: 0.021711  [1600/3750]\n",
      "loss: 0.004517  [1700/3750]\n",
      "loss: 0.000651  [1800/3750]\n",
      "loss: 0.002329  [1900/3750]\n",
      "loss: 0.030870  [2000/3750]\n",
      "loss: 0.005089  [2100/3750]\n",
      "loss: 0.001606  [2200/3750]\n",
      "loss: 0.004057  [2300/3750]\n",
      "loss: 0.003569  [2400/3750]\n",
      "loss: 0.005304  [2500/3750]\n",
      "loss: 0.019215  [2600/3750]\n",
      "loss: 0.000912  [2700/3750]\n",
      "loss: 0.193254  [2800/3750]\n",
      "loss: 0.215227  [2900/3750]\n",
      "loss: 0.001639  [3000/3750]\n",
      "loss: 0.000511  [3100/3750]\n",
      "loss: 0.211918  [3200/3750]\n",
      "loss: 0.000483  [3300/3750]\n",
      "loss: 0.000250  [3400/3750]\n",
      "loss: 0.009586  [3500/3750]\n",
      "loss: 0.032639  [3600/3750]\n",
      "loss: 0.002098  [3700/3750]\n",
      "Test: \n",
      " Accuracy: 98.1%, Avg loss: 0.056556 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.模型预测\n",
    "\n",
    "MindSpore提供save_checkpoint()函数保存模型和load_checkpoint()函数载入模型，我们载入刚才训练好的模型，对测试集再次进行预测。"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T12:46:18.364340Z",
     "start_time": "2025-01-13T12:46:18.355791Z"
    }
   },
   "source": [
    "\n",
    "# 模型保存\n",
    "mindspore.save_checkpoint(model, \"model.ckpt\")\n",
    "print(\"Saved Model to model.ckpt\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Model to model.ckpt\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T12:46:20.550105Z",
     "start_time": "2025-01-13T12:46:20.527093Z"
    }
   },
   "source": [
    "\n",
    "# 实例化模型\n",
    "model = AlexNet()\n",
    "# 载入训练好的模型\n",
    "param_dict = mindspore.load_checkpoint(\"model.ckpt\")\n",
    "param_not_load = mindspore.load_param_into_net(model, param_dict)\n",
    "print(param_not_load)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([], [])\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T12:46:22.737504Z",
     "start_time": "2025-01-13T12:46:22.698653Z"
    }
   },
   "source": [
    "model.set_train(False)\n",
    "for data, label in test_dataset:\n",
    "    pred = model(data)\n",
    "    predicted = pred.argmax(1)\n",
    "    print(f'Predicted: \"{predicted[:10]}\", Actual: \"{label[:10]}\"')\n",
    "    break\n",
    "\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: \"[2 2 8 1 9 3 6 6 0 4]\", Actual: \"[2 2 8 1 9 3 6 6 0 4]\"\n"
     ]
    }
   ],
   "execution_count": 11
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "26fcd935751ef84cad2d7f9e4bd00a41b458c58fd62c8d14685a9368156264ec"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
