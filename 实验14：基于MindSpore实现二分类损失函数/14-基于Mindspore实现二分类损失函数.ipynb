{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a7f683d2",
   "metadata": {},
   "source": [
    "# 基于Mindspore实现二分类损失函数\n",
    "\n",
    "通过实验了解分类损失函数原理，并能够基于Mindspore框架实现分类损失函数的计算以及训练和预测。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf603b85",
   "metadata": {},
   "source": [
    "## 1、实验目的\n",
    "* 学会内置损失函数的使用。\n",
    "* 掌握Mindspore中多种损失函数的特点和应用场景。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67132699",
   "metadata": {},
   "source": [
    "## 2、二分类损失函数原理介绍\n",
    "损失函数（loss function）或也称为代价函数（cost function），亦称目标函数，是将随机事件或其有关随机变量的取值映射为非负实数以表示该随机事件的“风险”或“损失”的函数，用于衡量预测值与真实值差异的程度。在实际的机器学习应用中，损失函数通常会作为学习准则与优化问题相联系，通过最小化损失函数求解和评估模型。\n",
    "\n",
    "(1) $n n$. L1Loss:计算预测值和目标值之间的平均绝对误差:\n",
    "$$\n",
    "\\ell(x, y)=L=\\left\\{l_1, \\ldots, l_N\\right\\}^{\\top}, \\quad \\text { with } l_n=\\left|x_n-y_n\\right|\n",
    "$$\n",
    "其中N为数据集中的 batch_size 值。\n",
    "$$\n",
    "\\ell(x, y)= \\begin{cases}\\operatorname{mean}(L), & \\text { if reduction }=\\text { 'mean'; } \\\\ \\operatorname{sum}(L), & \\text { if reduction='sum' }\\end{cases}\n",
    "$$\n",
    "nn.L1Loss 中的参数 reduction 取值可为 mean， sum，或 none 。若 reduction 为 mean 或 sum，则输出一个经过均值或求和后的标量 Tensor (降维) ；若 reduction 为 none，则所输出Tensor的shape为广播后的shape。\n",
    "\n",
    "(2)平均绝对误差MAE(Mean Absolute Error):计算模型预测值 f(x) 与样本真实值 y 之间距离的平均值。\n",
    "$$\\mathrm{MAE}=\\frac{1}{m} \\sum_{i=1}^{m}\\left|y_{i}-f\\left(x_{i}\\right)\\right|$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddecf6a0",
   "metadata": {},
   "source": [
    "## 3、实验环境\n",
    "在动手进行实践之前，需要注意以下几点：\n",
    "* 确保实验环境正确安装，包括安装MindSpore。安装过程：首先登录[MindSpore官网安装页面](https://www.mindspore.cn/install)，根据安装指南下载安装包及查询相关文档。同时，官网环境安装也可以按下表说明找到对应环境搭建文档链接，根据环境搭建手册配置对应的实验环境。\n",
    "* 推荐使用交互式的计算环境Jupyter Notebook，其交互性强，易于可视化，适合频繁修改的数据分析实验环境。\n",
    "* 实验也可以在华为云一站式的AI开发平台ModelArts上完成。\n",
    "* 推荐实验环境：MindSpore版本=MindSpore 2.4；Python环境=3.11\n",
    "\n",
    "\n",
    "|  硬件平台 |  操作系统  | 软件环境 | 开发环境 | 环境搭建链接 |\n",
    "| :-----:| :----: | :----: |:----:   |:----:   |\n",
    "| CPU | Windows-x64 | MindSpore2.4 Python3.11 | JupyterNotebook |[MindSpore环境搭建实验手册第二章2.1节和第三章3.1节](./MindSpore环境搭建实验手册.docx)|\n",
    "| GPU CUDA 10.1|Linux-x86_64| MindSpore2.4 Python3.11 | JupyterNotebook |[MindSpore环境搭建实验手册第二章2.2节和第三章3.1节](./MindSpore环境搭建实验手册.docx)|\n",
    "| Ascend 910  | Linux-x86_64| MindSpore2.4 Python3.11 | JupyterNotebook |[MindSpore环境搭建实验手册第四章](./MindSpore环境搭建实验手册.docx)|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "134ff345",
   "metadata": {},
   "source": [
    "## 4、数据处理\n",
    "\n",
    "### 4.1数据准备\n",
    "\n",
    "   在本次实验中，我们使用numpy从均匀分布中随机生成测试数据x，从正态分布中随机生成噪声加入因变量y。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "afd7bee8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(array([6.374636], dtype=float32), array([16.205915], dtype=float32)),\n",
       " (array([-5.7773037], dtype=float32), array([-9.919436], dtype=float32)),\n",
       " (array([-0.23789468], dtype=float32), array([3.2614572], dtype=float32)),\n",
       " (array([-8.137355], dtype=float32), array([-12.005216], dtype=float32)),\n",
       " (array([8.518956], dtype=float32), array([20.397629], dtype=float32))]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np                         # Python 的科学计算库，用于处理矩阵和数组等数据结构。\n",
    "def get_data(num, w=2.0, b=3.0):           # 生成数据及对应标签   \n",
    "    for _ in range(num):                   #  num=160,生成160个样本点\n",
    "        x = np.random.uniform(-10.0, 10.0) # 生成服从(-10.0, 10.0)范围内的均匀分布的元素，返回值的元素类型为浮点型。\n",
    "        noise = np.random.normal(0, 1)     # 随机产生一个服从正态分布(0,1)的数值\n",
    "        y = x * w + b + noise              # 增加噪音生成y\n",
    "        yield np.array([x]).astype(np.float32), np.array([y]).astype(np.float32)#将数组元素类型转换为float32位;\n",
    "                                           # 我们为了提高效率，并不一次性返回所有数据，而是采用迭代器形式返回单一数据。\n",
    "#可视化部分生成数据\n",
    "eval_data=list(get_data(5))\n",
    "#zip()函数迭代eval_data，将eval_data中的元素打包成一个个元组，然后返回由这些元组组成的列表。\n",
    "x,y=zip(*eval_data)\n",
    "#可视化生成的5个样本点\n",
    "eval_data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc2ecf1",
   "metadata": {},
   "source": [
    "### 4.2数据加载\n",
    "使用GeneratorDataset，通过迭代列表构造数据集，指定生成数据集的列名为data和lable，使用batch函数指定每个批处理数据包含的数据条目。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2db70731",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mindspore import dataset as ds\n",
    "def create_dataset(num_data, batch_size=16):                           #加载数据集\n",
    "    data=list(get_data(num_data))\n",
    "    dataset = ds.GeneratorDataset(data, column_names=['data', 'label'])#指定生成数据集的列名为data和lable\n",
    "    dataset = dataset.batch(batch_size)                                #设置数据批次\n",
    "    return dataset        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4840d74",
   "metadata": {},
   "source": [
    "## 5、几个损失函数\n",
    "\n",
    "### 5.1内置损失函数\n",
    "下面介绍 mindspore. $\\mathrm{nn}$ 模块中内置的损失函数L1损失。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ba89f68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.33333334\n",
      "loss_sum: 2.0\n",
      "loss_none:\n",
      " [1. 0. 0. 1. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# 1.内置损失函数\n",
    "import mindspore as ms\n",
    "import mindspore.nn as nn \n",
    "loss = nn.L1Loss()                       # 输出loss均值\n",
    "loss_sum = nn.L1Loss(reduction='sum')    # 输出loss和\n",
    "loss_none = nn.L1Loss(reduction='none')  # 输出loss原值\n",
    "input_data = ms.Tensor(np.array([1, 0, 1, 0, 1, 0]).astype(np.float32)) # 定义输入数据\n",
    "target_data = ms.Tensor(np.array([0, 0, 1, 1, 1, 0]).astype(np.float32)) # 定义标签\n",
    "print(\"loss:\", loss(input_data, target_data))             # 打印loss均值\n",
    "print(\"loss_sum:\", loss_sum(input_data, target_data))     # 打印所有loss和\n",
    "print(\"loss_none:\\n\", loss_none(input_data, target_data)) # 打印每个样本点loss的原值"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e861f25e",
   "metadata": {},
   "source": [
    "### 5.2基于nn.Cell构造损失函数\n",
    "\n",
    "nn.Cell 是MindSpore的基类，不但可用于构建网络，还可用于定义损失函数。使用 $n n$.Cell定义损失函数的过程与定义一个普通的网络相似，差别在于，其执行逻辑部分要计算的是前向网络输出与真实值之间的误差。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47e762fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.33333334\n"
     ]
    }
   ],
   "source": [
    "# 2.基于nn.Cell构造损失函数\n",
    "import mindspore.ops as ops\n",
    "class MAELoss(nn.Cell):                 # 自定义损失函数MAELoss\n",
    "    def __init__(self):                 # 初始化\n",
    "        super(MAELoss, self).__init__()\n",
    "        self.abs = ops.abs\n",
    "        self.reduce_mean = ops.ReduceMean()\n",
    "    def construct(self, base, target):  # 调用算子        \n",
    "        x = self.abs(base - target)\n",
    "        return self.reduce_mean(x)\n",
    "loss = MAELoss()                        # 定义损失函数\n",
    "input_data = ms.Tensor(np.array([1, 0, 1, 0, 1, 0]).astype(np.float32))  # 定义输入数据\n",
    "target_data = ms.Tensor(np.array([0, 0, 1, 1, 1, 0]).astype(np.float32)) # 定义标签\n",
    "output = loss(input_data, target_data)  # 计算损失\n",
    "print(output)                           # 打印损失"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f35dcfb3",
   "metadata": {},
   "source": [
    "### 5.3基于nn.LossBase构造损失函数\n",
    "\n",
    "基于nn.LossBase构造损失函数MAELoss与基于nn.Cell构造损失函数的过程类似，都要重写__init__方法和construct方法。\n",
    "\n",
    "nn.LossBase可使用方法get_loss将reduction应用于损失计算。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "532ecadd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.33333334\n"
     ]
    }
   ],
   "source": [
    "# 3.基于nn.LossBase构造损失函数\n",
    "class MAELoss(nn.LossBase):               # 自定义损失函数MAELoss\n",
    "    def __init__(self, reduction=\"mean\"): # 初始化并求loss均值       \n",
    "        super(MAELoss, self).__init__(reduction)\n",
    "        self.abs = ops.abs              # 求绝对值算子\n",
    "    def construct(self, base, target):    # 调用算子\n",
    "        x = self.abs(base - target)\n",
    "        return self.get_loss(x)           # 返回loss均值\n",
    "loss = MAELoss()                          # 定义损失函数\n",
    "input_data = ms.Tensor(np.array([1, 0, 1, 0, 1, 0]).astype(np.float32))  # 生成预测值\n",
    "target_data = ms.Tensor(np.array([0, 0, 1, 1, 1, 0]).astype(np.float32))  # 生成真实值\n",
    "output = loss(input_data, target_data)    # 计算损失\n",
    "print(output)                             # 打印损失"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d6a1464",
   "metadata": {},
   "source": [
    "## 6、模型构建\n",
    "\n",
    "本次实验使用MindSpore中内置的L1loss损失函数和接口Model中fit接口进行模型训练，构造Model时需传入前向网络、损失函数和优化器，Model会在内部将它们关联起来，生成一个可用于训练的网络模型。指定一个回调函数LossMonitor来监控训练过程中的loss值，并将训练集大小传递给它,LossMonitor函数计算并输出每个epoch中的平均训练损失和损失。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ca2c180b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1.定义模型\n",
    "#使用了MindSpore的神经网络模块中的dense函数，该函数用于创建全连接。这里创建了一个输入维度为1，输出维度为1的全连接层。\n",
    "net = nn.Dense(1, 1)\n",
    "\n",
    "#2.定义损失函数\n",
    "#使用了MindSpore的神经网络模块中的L1Loss函数，该函数用于计算 L1 Loss（也称为绝对值误差）。\n",
    "loss_fn = nn.L1Loss()\n",
    "\n",
    "#3.定义优化器\n",
    "#使用了MindSpore的优化器模块中的Momentum函数，它是一个带动量随机梯度下降法（SGD）。\n",
    "#Momentum算法的基本思路是使用上一步的梯度方向来决定本步的梯度方向，从而解决随机梯度下降法中的震荡问题。\n",
    "#它可以加速收敛，而且对于参数的自适应能力也更强。\n",
    "#learning_rate为学习率，momentum为动量参数。\n",
    "optimizer = nn.Momentum(net.trainable_params(), learning_rate=0.005, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd7c7457",
   "metadata": {},
   "source": [
    "## 7、模型训练\n",
    "生成num_data个数据点，实例化线性网络，选择L1Loss和Momentum优化器进行训练。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e8d351dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mindspore.train import Model, MAE, LossMonitor \n",
    "\n",
    "#将定义好的神经网络模型、损失函数和优化器用Model函数封装，指定了评价指标为MAE（平均绝对误差）。\n",
    "#这个函数在训练过程中会自动计算每个batch的损失值和评价指标，并使用优化器更新模型参数。\n",
    "model = Model(net, loss_fn, optimizer, metrics={\"MAE\": MAE()})\n",
    "train_dataset = create_dataset(num_data=160)          # 生成训练集\n",
    "eval_dataset = create_dataset(num_data=160)           # 生成测试集\n",
    "train_dataset_size = train_dataset.get_dataset_size() # 训练集大小\n",
    "\n",
    "# 定义forward函数\n",
    "def forward_fn(inputs, targets):\n",
    "    logits = net(inputs)\n",
    "    loss = loss_fn(logits, targets)\n",
    "    return loss\n",
    "\n",
    "grad_fn = ms.value_and_grad(forward_fn, None, optimizer.parameters)\n",
    "\n",
    "def train_step(inputs, targets):\n",
    "    loss, grads = grad_fn(inputs, targets)\n",
    "    optimizer(grads)\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "582f8e71",
   "metadata": {},
   "source": [
    "## 8、模型预测\n",
    "使用封装好的模型对训练集进行训练，并在验证集上进行评估训练。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b6ebeac-6c88-4337-8789-e699ca64329f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Step: 0, Loss: 10.05474\n",
      "Epoch: 0, MAE: 5.344454717636109\n",
      "Epoch: 1, Step: 0, Loss: 5.2119384\n",
      "Epoch: 1, MAE: 3.40930290222168\n",
      "Epoch: 2, Step: 0, Loss: 2.7828224\n",
      "Epoch: 2, MAE: 3.2873810052871706\n",
      "Epoch: 3, Step: 0, Loss: 3.3883517\n",
      "Epoch: 3, MAE: 2.771801400184631\n",
      "Epoch: 4, Step: 0, Loss: 2.847849\n",
      "Epoch: 4, MAE: 2.3322375535964968\n",
      "Epoch: 5, Step: 0, Loss: 2.190043\n",
      "Epoch: 5, MAE: 1.8599430322647095\n",
      "Epoch: 6, Step: 0, Loss: 2.0208054\n",
      "Epoch: 6, MAE: 1.4688191175460816\n",
      "Epoch: 7, Step: 0, Loss: 1.6750548\n",
      "Epoch: 7, MAE: 1.1897496640682221\n",
      "Epoch: 8, Step: 0, Loss: 1.3291664\n",
      "Epoch: 8, MAE: 0.9495349526405334\n",
      "Epoch: 9, Step: 0, Loss: 1.082624\n",
      "Epoch: 9, MAE: 0.8861383855342865\n"
     ]
    }
   ],
   "source": [
    "#指定了一个回调函数LossMonitor来监控训练过程中的loss值，并将训练集大小传递给它。回调函数可以在特定的阶段中被调用，如个epoch结束时。\n",
    "#此处LossMonitor函数计算并输出每个epoch中的平均训练损失和损失。\n",
    "\n",
    "from mindspore import ops, nn\n",
    "\n",
    "# 定义验证函数\n",
    "def eval_step(model, data, label):\n",
    "    output = model.predict(data)\n",
    "    metric = model._metrics['MAE']\n",
    "    metric.update(output, label)\n",
    "    return metric.eval()\n",
    "\n",
    "# 主训练循环\n",
    "for epoch in range(10):\n",
    "    # 训练阶段\n",
    "    for batch, (data, label) in enumerate(train_dataset):\n",
    "        loss = train_step(data, label)\n",
    "        if batch % 10 == 0:\n",
    "            print(f\"Epoch: {epoch}, Step: {batch}, Loss: {loss}\")\n",
    "\n",
    "    # 验证阶段\n",
    "\n",
    "    model._metrics['MAE'].clear()  # 清空指标缓存\n",
    "    for data, label in eval_dataset:\n",
    "        eval_result = eval_step(model, data, label)\n",
    "    print(f\"Epoch: {epoch}, MAE: {eval_result}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbb1d193",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
