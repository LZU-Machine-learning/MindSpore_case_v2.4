{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 基于MindSpore实现多分类损失函数\n",
    "本小节主要介绍多分类损失函数的原理，并使用MIndspore实现。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1、实验目的\n",
    "- 了解多分类损失函数原理。\n",
    "- 掌握如何使用MIndspore实现多分类损失函数。\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2、多分类损失函数原理介绍\n",
    "二分类损失函数中定义了一个简单的平均绝对误差损失函数MAELoss，但许多深度学习应用的数据集较复杂，如目标检测网络Faster R-CNN的数据中就包含多个标签，而非简单的一条数据对应一个标签，这时损失函数的定义和使用略有不同。  \n",
    "针对本实验中创建的多标签数据集，定义多标签损失函数MAELossForMultiLabel。\n",
    "$$ loss\\ 1=\\frac{1}{m}\\ \\sum_{i=1}^{m}\\left|y1_i-f\\left(x_i\\right)\\right| $$\n",
    "$$ loss\\ 2=\\frac{1}{m}\\ \\sum_{i=1}^{m}\\left|y2_i-f\\left(x_i\\right)\\right| $$\n",
    "$$ loss=\\frac{\\left(loss1+loss2\\right)}{2} $$\n",
    "上式中，f(x)为样例标签的预测值，y1和y2为样例标签的真实值，$loss\\ 1$为预测值与真实值y1之间距离的平均值，$loss\\ 2$为预测值与真实值y2之间距离的平均值，loss为损失值$loss\\ 1$与损失值$loss\\ 2$平均值。  \n",
    "在 MAELossForMultilabel中的construct方法的输入有三个，预测值base，真实值target1和target2，在construct中分别计算预测值与真实值target1、预测值与真实值target2之间的误差，将两误差取平均后作为最终的损失函数值。\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3、实验环境\n",
    "在动手进行实践之前，需要注意以下几点：\n",
    "* 确保实验环境正确安装，包括安装MindSpore。安装过程：首先登录[MindSpore官网安装页面](https://www.mindspore.cn/install)，根据安装指南下载安装包及查询相关文档。同时，官网环境安装也可以按下表说明找到对应环境搭建文档链接，根据环境搭建手册配置对应的实验环境。\n",
    "* 推荐使用交互式的计算环境Jupyter Notebook，其交互性强，易于可视化，适合频繁修改的数据分析实验环境。\n",
    "* 实验也可以在华为云一站式的AI开发平台ModelArts上完成。\n",
    "* 推荐实验环境：MindSpore版本=MindSpore 2.4.10；Python环境=3.11\n",
    "\n",
    "\n",
    "|  硬件平台 |  操作系统  | 软件环境 | 开发环境 | 环境搭建链接 |\n",
    "| :-----:| :----: | :----: |:----:   |:----:   |\n",
    "| CPU | Windows-x64 | MindSpore2.4.10 Python3.11 | JupyterNotebook |[MindSpore环境搭建实验手册第二章2.1节和第三章3.1节](./MindSpore环境搭建实验手册.docx)|\n",
    "| GPU|Linux-x86_64| MindSpore2.4.10 Python3.11 | JupyterNotebook |[MindSpore环境搭建实验手册第二章2.2节和第三章3.1节](./MindSpore环境搭建实验手册.docx)|\n",
    "| Ascend 910  | Linux-x86_64| MindSpore2.4.10 Python3.11 | JupyterNotebook |[MindSpore环境搭建实验手册第四章](./MindSpore环境搭建实验手册.docx)|"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4、数据处理"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 构建多标签数据集\n",
    "Numpy模块主要用于数据的基本运算操作。MindSpore相关模块主要用于搭建网络、调用优化器、读取数据集和将数据集处理成网络的标准输入格式。  \n",
    "数据集的两个标签分别由\n",
    "$$y_1=2x+3+{noise}_1$$\n",
    "$$y_2=2x+3+{noise}_2$$\n",
    "生成。其中${noise}_1$和${noise}_2$为服从标准正态分布的随机值。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from mindspore import dataset as ds\n",
    "import mindspore.nn as nn\n",
    "import mindspore as ms\n",
    "\n",
    "ms.set_context(mode=ms.GRAPH_MODE, device_target='CPU')\n",
    "\n",
    "# 生成带有两个标签的数据集\n",
    "def get_multilabel_data(num, w=2.0, b=3.0):\n",
    "    for _ in range(num):\n",
    "        x = np.random.uniform(-10.0, 10.0)\n",
    "        # noise1和noise2为服从标准正态分布的随机值\n",
    "        noise1 = np.random.normal(0, 1)\n",
    "        noise2 = np.random.normal(-1, 1)\n",
    "        # 定义第一个标签\n",
    "        y1 = x * w + b + noise1                   \n",
    "        # 定义第二个标签\n",
    "        y2 = x * w + b + noise2                   \n",
    "        yield np.array([x]).astype(np.float32), np.array([y1]).astype(np.float32), np.array([y2]).astype(np.float32)\n",
    "\n",
    "def create_multilabel_dataset(num_data, batch_size=16):\n",
    "    dataset = ds.GeneratorDataset(list(get_multilabel_data(num_data)), column_names=['data', 'label1', 'label2'])\n",
    "    # 每个batch有16个数据\n",
    "    dataset = dataset.batch(batch_size) \n",
    "    return dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5、模型构建"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 多标签损失函数\n",
    "定义多标签损失函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义多标签损失函数\n",
    "class MAELossForMultiLabel(nn.LossBase):\n",
    "    def __init__(self, reduction=\"mean\"):\n",
    "        super(MAELossForMultiLabel, self).__init__(reduction)\n",
    "        self.abs = ops.abs\n",
    "\n",
    "    def construct(self, base, target1, target2):\n",
    "        # 计算第一个标签的误差\n",
    "        x1 = self.abs(base - target1)\n",
    "        # 计算第二个标签的误差\n",
    "        x2 = self.abs(base - target2)\n",
    "        # 将两误差取平均后作为最终的损失函数值                           \n",
    "        return (self.get_loss(x1) + self.get_loss(x2))/2        "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 定义损失函数\n",
    "使用 Model 关联指定的前向网络、损失函数和优化器时，因 Model 内默认使用的 nn.WithLossCell 只接受两个输入： data 和 label ，故不适用于多标签场景。在多标签场景下，若想使用 Model 进行模型训练，则需事先把前向网络与多标签损失函数关联起来，即自定义损失网络。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 自定义损失网络\n",
    "class CustomWithLossCell(nn.Cell):\n",
    "    def __init__(self, backbone, loss_fn):\n",
    "        super(CustomWithLossCell, self).__init__(auto_prefix=False)\n",
    "        self._backbone = backbone\n",
    "        self._loss_fn = loss_fn\n",
    "\n",
    "    def construct(self, data, label1, label2):\n",
    "        output = self._backbone(data)\n",
    "        return self._loss_fn(output, label1, label2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 定义网络模型\n",
    "定义线性回归网络。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mindspore.common.initializer import Normal\n",
    "import mindspore.ops as ops\n",
    "from mindspore.train import LossMonitor\n",
    "# 定义线性回归网络\n",
    "class LinearNet(nn.Cell):\n",
    "    def __init__(self):\n",
    "        super(LinearNet, self).__init__()\n",
    "        self.fc = nn.Dense(1, 1, Normal(0.02), Normal(0.02))\n",
    "\n",
    "    def construct(self, x):\n",
    "        return self.fc(x)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6、模型训练\n",
    "定义多标签损失函数、损失网络和优化器，并开始模型的训练。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 step: 1, loss is 10.276220321655273\n",
      "epoch: 1 step: 2, loss is 10.745540618896484\n",
      "epoch: 1 step: 3, loss is 9.607166290283203\n",
      "epoch: 1 step: 4, loss is 8.386201858520508\n",
      "epoch: 1 step: 5, loss is 12.938684463500977\n",
      "epoch: 1 step: 6, loss is 10.977479934692383\n",
      "epoch: 1 step: 7, loss is 9.584671020507812\n",
      "epoch: 1 step: 8, loss is 8.20848560333252\n",
      "epoch: 1 step: 9, loss is 5.252236366271973\n",
      "epoch: 1 step: 10, loss is 5.437386512756348\n",
      "epoch: 2 step: 1, loss is 3.8374743461608887\n",
      "epoch: 2 step: 2, loss is 3.168424129486084\n",
      "epoch: 2 step: 3, loss is 3.8121705055236816\n",
      "epoch: 2 step: 4, loss is 2.7532572746276855\n",
      "epoch: 2 step: 5, loss is 3.608736753463745\n",
      "epoch: 2 step: 6, loss is 2.401789665222168\n",
      "epoch: 2 step: 7, loss is 2.7597250938415527\n",
      "epoch: 2 step: 8, loss is 2.4011073112487793\n",
      "epoch: 2 step: 9, loss is 1.8929429054260254\n",
      "epoch: 2 step: 10, loss is 2.575892448425293\n",
      "epoch: 3 step: 1, loss is 2.408012866973877\n",
      "epoch: 3 step: 2, loss is 3.2946763038635254\n",
      "epoch: 3 step: 3, loss is 4.766338348388672\n",
      "epoch: 3 step: 4, loss is 4.2391462326049805\n",
      "epoch: 3 step: 5, loss is 4.043171405792236\n",
      "epoch: 3 step: 6, loss is 3.3910868167877197\n",
      "epoch: 3 step: 7, loss is 3.0003952980041504\n",
      "epoch: 3 step: 8, loss is 2.0975067615509033\n",
      "epoch: 3 step: 9, loss is 1.8882384300231934\n",
      "epoch: 3 step: 10, loss is 1.9192323684692383\n",
      "epoch: 4 step: 1, loss is 2.5371785163879395\n",
      "epoch: 4 step: 2, loss is 1.964829921722412\n",
      "epoch: 4 step: 3, loss is 2.2178869247436523\n",
      "epoch: 4 step: 4, loss is 2.359272003173828\n",
      "epoch: 4 step: 5, loss is 1.8671938180923462\n",
      "epoch: 4 step: 6, loss is 2.0807552337646484\n",
      "epoch: 4 step: 7, loss is 2.216163158416748\n",
      "epoch: 4 step: 8, loss is 2.8536925315856934\n",
      "epoch: 4 step: 9, loss is 2.063985824584961\n",
      "epoch: 4 step: 10, loss is 2.4397025108337402\n",
      "epoch: 5 step: 1, loss is 2.019054651260376\n",
      "epoch: 5 step: 2, loss is 1.9799890518188477\n",
      "epoch: 5 step: 3, loss is 2.2787458896636963\n",
      "epoch: 5 step: 4, loss is 1.7396864891052246\n",
      "epoch: 5 step: 5, loss is 1.5669828653335571\n",
      "epoch: 5 step: 6, loss is 1.7975962162017822\n",
      "epoch: 5 step: 7, loss is 1.5835787057876587\n",
      "epoch: 5 step: 8, loss is 1.6484854221343994\n",
      "epoch: 5 step: 9, loss is 1.6185754537582397\n",
      "epoch: 5 step: 10, loss is 1.560897946357727\n",
      "epoch: 6 step: 1, loss is 1.7106821537017822\n",
      "epoch: 6 step: 2, loss is 1.538656234741211\n",
      "epoch: 6 step: 3, loss is 1.6251029968261719\n",
      "epoch: 6 step: 4, loss is 1.42574143409729\n",
      "epoch: 6 step: 5, loss is 1.1830956935882568\n",
      "epoch: 6 step: 6, loss is 1.4162437915802002\n",
      "epoch: 6 step: 7, loss is 1.6990869045257568\n",
      "epoch: 6 step: 8, loss is 1.2828680276870728\n",
      "epoch: 6 step: 9, loss is 1.4715688228607178\n",
      "epoch: 6 step: 10, loss is 1.17545747756958\n",
      "epoch: 7 step: 1, loss is 1.2471617460250854\n",
      "epoch: 7 step: 2, loss is 1.285383939743042\n",
      "epoch: 7 step: 3, loss is 1.1470470428466797\n",
      "epoch: 7 step: 4, loss is 1.343719720840454\n",
      "epoch: 7 step: 5, loss is 1.349381923675537\n",
      "epoch: 7 step: 6, loss is 1.237510085105896\n",
      "epoch: 7 step: 7, loss is 0.9583227634429932\n",
      "epoch: 7 step: 8, loss is 0.8875399827957153\n",
      "epoch: 7 step: 9, loss is 1.2223464250564575\n",
      "epoch: 7 step: 10, loss is 1.2550039291381836\n",
      "epoch: 8 step: 1, loss is 0.9926871061325073\n",
      "epoch: 8 step: 2, loss is 0.9937257766723633\n",
      "epoch: 8 step: 3, loss is 0.9220473766326904\n",
      "epoch: 8 step: 4, loss is 1.3629448413848877\n",
      "epoch: 8 step: 5, loss is 1.072584867477417\n",
      "epoch: 8 step: 6, loss is 0.9975234270095825\n",
      "epoch: 8 step: 7, loss is 0.9577374458312988\n",
      "epoch: 8 step: 8, loss is 0.9352051019668579\n",
      "epoch: 8 step: 9, loss is 0.8947707414627075\n",
      "epoch: 8 step: 10, loss is 1.0953946113586426\n",
      "epoch: 9 step: 1, loss is 1.2354404926300049\n",
      "epoch: 9 step: 2, loss is 0.8519678115844727\n",
      "epoch: 9 step: 3, loss is 0.7764584422111511\n",
      "epoch: 9 step: 4, loss is 0.9085703492164612\n",
      "epoch: 9 step: 5, loss is 0.8583962321281433\n",
      "epoch: 9 step: 6, loss is 0.7428209185600281\n",
      "epoch: 9 step: 7, loss is 0.85166335105896\n",
      "epoch: 9 step: 8, loss is 0.9067959189414978\n",
      "epoch: 9 step: 9, loss is 1.194718360900879\n",
      "epoch: 9 step: 10, loss is 1.1930922269821167\n",
      "epoch: 10 step: 1, loss is 0.87856525182724\n",
      "epoch: 10 step: 2, loss is 0.9392503499984741\n",
      "epoch: 10 step: 3, loss is 1.1501117944717407\n",
      "epoch: 10 step: 4, loss is 0.9905089139938354\n",
      "epoch: 10 step: 5, loss is 0.8382529020309448\n",
      "epoch: 10 step: 6, loss is 0.7824758291244507\n",
      "epoch: 10 step: 7, loss is 0.9840420484542847\n",
      "epoch: 10 step: 8, loss is 0.7937813997268677\n",
      "epoch: 10 step: 9, loss is 0.9683185815811157\n",
      "epoch: 10 step: 10, loss is 0.7245912551879883\n"
     ]
    }
   ],
   "source": [
    "ds_train = create_multilabel_dataset(num_data=160)\n",
    "net = LinearNet()\n",
    "# 定义多标签损失函数\n",
    "loss = MAELossForMultiLabel()\n",
    "# 定义损失网络，连接前向网络和多标签损失函数\n",
    "loss_net = CustomWithLossCell(net, loss)\n",
    "# 定义优化器\n",
    "opt = nn.Momentum(net.trainable_params(), learning_rate=0.005, momentum=0.9)\n",
    "# 定义Model，多标签场景下Model无需指定损失函数\n",
    "model = ms.train.Model(network=loss_net, optimizer=opt)\n",
    "\n",
    "model.train(epoch=10, train_dataset=ds_train, callbacks=[LossMonitor(1)])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7、模型预测\n",
    "使用模型进行预测。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data:[[-7.94969619]]\n",
      "predict result:[[[-13.43283]]]\n",
      "true result1:[[-12.89939238]]\n",
      "true result2:[[-12.89939238]]\n"
     ]
    }
   ],
   "source": [
    "from mindspore import Tensor,context\n",
    "\n",
    "# 生成测试数据\n",
    "w=2.0\n",
    "b=3.0\n",
    "x = np.random.uniform(-10.0, 10.0, (1,1))\n",
    "x1 = np.array([x]).astype(np.float32)\n",
    "#模型测试\n",
    "test_result = net(Tensor(x1))\n",
    "# 定义第一个标签\n",
    "true_result1 = x * w + b      \n",
    "# 定义第二个标签\n",
    "true_result2 = x * w + b\n",
    "\n",
    "print('data:' + '%s'%x)\n",
    "print('predict result:' + '%s'%test_result)\n",
    "print('true result1:' + '%s'%true_result1)\n",
    "print('true result2:' + '%s'%true_result2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
