{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c43f128",
   "metadata": {},
   "source": [
    "# 3. 基于MindSpore构造非对称损失函数"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0daf21d1",
   "metadata": {},
   "source": [
    " 本实验主要介绍非对称损失函数的原理和构造，使用MindSpore构造非对称损失函数，以Focal Loss损失函数作为讲解实例。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b6cf308",
   "metadata": {},
   "source": [
    "## 1、实验目的"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9317ad8",
   "metadata": {},
   "source": [
    "- 掌握非对称损失函数的原理。\n",
    "- 掌握如何使用MindSpore构造非对称损失函数。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9653a95d",
   "metadata": {},
   "source": [
    "## 2、非对称损失函数原理介绍"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eac9ca6",
   "metadata": {},
   "source": [
    "非对称损失函数可以看做是一种最优化方法，通过控制参数变化，使模型获得适合的拟合行为，从而降低误差和达到最优效果。它是在构建模型权重时，从损失函数中提取出来的一种损失函数，它可以调整模型拟合程度，改善模型预测精确度。\n",
    "\n",
    "Focal Loss函数：Focal Loss是基于二分类交叉熵损失的。它是一个动态缩放的交叉熵损失，通过一个动态缩放因子，可以动态降低训练过程中易区分样本的权重，从而将重心快速聚焦在那些难区分的样本（有可能是正样本，也有可能是负样本，但都是对训练网络有帮助的样本），公式如下：\n",
    "$$FL(p_t)=-{{\\alpha}_t}(1-p_t)^{\\gamma}log(p_t)$$\n",
    "即通过${{\\alpha}_t}$可以抑制正负样本的数量失衡，通过${\\gamma}$可以控制简单/难区分样本数量失衡。\n",
    "\n",
    "${\\gamma}$为一个参数，范围在[0,5]， 当${\\gamma}$为0时，就变成了二分类交叉熵损失函数。$(1-p_t)^{\\gamma}$可以降低易分样本的损失贡献，从而增加难分样本的损失比例。当$p_t$趋向于1，即说明该样本是易区分样本，此时调制因子$(1-p_t)^{\\gamma}$是趋向于0，说明对损失的贡献较小，即降低了易区分样本的损失比例；当$p_t$很小，也就是假如某个样本被分到正样本，但是该样本为前景的概率特别小，即被错分到正样本了，此时调制因子$(1-p_t)^{\\gamma}$是趋向于1，对loss也没有太大的影响。\n",
    "\n",
    "Focal Loss的特点：\n",
    "\n",
    "（1）调制因子$(1-p_t)^{\\gamma}$是用来减低易分样本的损失贡献 ，无论是前景类还是背景类，$p_t$越大，就说明该样本越容易被区分，调制因子也就越小。\n",
    "\n",
    "（2）${{\\alpha}_t}$用于调节正负样本损失之间的比例，前景类别使用${{\\alpha}_t}$时，对应的背景类别使用$1-{{\\alpha}_t}$。\n",
    "\n",
    "（3）${\\gamma}$和${{\\alpha}_t}$都有相应的取值范围，他们的取值相互间也是有影响的，在实际使用过程中应组合使用。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b90b815",
   "metadata": {},
   "source": [
    "## 3、实验环境"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee3b592",
   "metadata": {},
   "source": [
    "在动手进行实践之前，需要注意以下几点：\n",
    "* 确保实验环境正确安装，包括安装MindSpore。安装过程：首先登录[MindSpore官网安装页面](https://www.mindspore.cn/install)，根据安装指南下载安装包及查询相关文档。同时，官网环境安装也可以按下表说明找到对应环境搭建文档链接，根据环境搭建手册配置对应的实验环境。\n",
    "* 推荐使用交互式的计算环境Jupyter Notebook，其交互性强，易于可视化，适合频繁修改的数据分析实验环境。\n",
    "* 实验也可以在华为云一站式的AI开发平台ModelArts上完成。\n",
    "* 推荐实验环境：MindSpore版本=MindSpore 2.4；Python环境=3.11。\n",
    "\n",
    "\n",
    "|  硬件平台 |\n",
    "  操作系统  | 软件环境 | 开发环境 | 环境搭建链接 |\n",
    "| :-----:| :----: | :----: |:----:   |:----:   |\n",
    "| CPU | Windows-x64 | MindSpore2.4 Python3.11 | JupyterNotebook |[MindSpore环境搭建实验手册第二章2.1节和第三章3.1节](./MindSpore环境搭建实验手册.docx)|\n",
    "| GPU |Linux-x86_64| MindSpore2.4 Python3.11 | JupyterNotebook |[MindSpore环境搭建实验手册第二章2.2节和第三章3.1节](./MindSpore环境搭建实验手册.docx)|\n",
    "| Ascend 910  | Linux-x86_64| MindSpore2.4 Python3.11 | JupyterNotebook |[MindSpore环境搭建实验手册第四章](./MindSpore环境搭建实验手册.docx)|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f43a45b7",
   "metadata": {},
   "source": [
    "## 4、数据处理"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9f08a82",
   "metadata": {},
   "source": [
    "### 4.1 数据准备"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78fd60e8",
   "metadata": {},
   "source": [
    "在本次实验中，我们使用numpy从均匀分布中随机生成测试数据，从正态分布中随机生成噪声加入因变量y。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e83a91e",
   "metadata": {},
   "source": [
    "### 4.2 数据加载"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "237fc292",
   "metadata": {},
   "source": [
    "使用GeneratorDataset，通过迭代列表构造数据集，指定生成数据集的列名为data和lable，使用batch函数指定每个批处理数据包含的数据条目。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e211191",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(array([9.9895935], dtype=float32), array([1])),\n",
       " (array([-7.1175165], dtype=float32), array([0])),\n",
       " (array([7.8569226], dtype=float32), array([1])),\n",
       " (array([-7.842265], dtype=float32), array([0])),\n",
       " (array([2.4499097], dtype=float32), array([1]))]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 导入必要的库，包括NumPy和MindSpore\n",
    "import numpy as np\n",
    "from mindspore import dataset as ds\n",
    "import mindspore.nn as nn\n",
    "import mindspore as ms\n",
    "\n",
    "# 生成带有标签的数据集\n",
    "def get_data(num, w=2.0, b=3.0):\n",
    "    for _ in range(num):\n",
    "        x = np.random.uniform(-10.0, 10.0) # 生成服从(-10.0, 10.0)范围内的均匀分布的元素，返回值的元素类型为浮点型。       \n",
    "        #根据公式生成标签 \n",
    "        y = 1 if x * w + b >0 else 0     \n",
    "        yield np.array([x]).astype(np.float32), np.array([y]).astype(np.int32) \n",
    "\n",
    "def create_dataset(num_data, batch_size=16):\n",
    "    # 加载数据集\n",
    "    dataset = ds.GeneratorDataset(list(get_data(num_data)), column_names=['data', 'label']) \n",
    "    # 每个batch有16个数据\n",
    "    dataset = dataset.batch(batch_size) \n",
    "    return dataset\n",
    "\n",
    "# 可视化生成的数据\n",
    "eval_data=list(get_data(5))\n",
    "\n",
    "x,y=zip(*eval_data) #zip()函数迭代eval_data，将eval_data中的元素打包成一个个元组，然后返回由这些元组组成的列表。\n",
    "\n",
    "eval_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a2ac3f",
   "metadata": {},
   "source": [
    "## 5、模型构建"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb1b9674",
   "metadata": {},
   "source": [
    "### 5.1 导入Python库和模块"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f0b889b",
   "metadata": {},
   "source": [
    "在使用前，导入需要的Python库和模块。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "252cb19f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 时间处理模块\n",
    "import time\n",
    "# 科学计算库\n",
    "import numpy as np\n",
    "# MindSpore库\n",
    "import mindspore as ms\n",
    "# 常见算子操作\n",
    "import mindspore.ops as ops\n",
    "# 数据集处理模块\n",
    "from mindspore import dataset as ds\n",
    "# 神经网络模块，张量，模型编译\n",
    "from mindspore import Tensor\n",
    "# 模型训练设置\n",
    "from mindspore.train import Callback, LossMonitor\n",
    "# MindSpore环境设置的0号种子\n",
    "ms.common.set_seed(0)\n",
    "import mindspore.nn as nn\n",
    "from mindspore.common.initializer import Normal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af96e2c4",
   "metadata": {},
   "source": [
    "### 5.2 定义模型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1597ea3",
   "metadata": {},
   "source": [
    "定义线性回归网络和构造函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f147c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义线性回归网络\n",
    "class LinearNet(nn.Cell):\n",
    "    def __init__(self):\n",
    "        super(LinearNet, self).__init__()\n",
    "        self.fc = nn.Dense(1, 1, Normal(0.02), Normal(0.02))        \n",
    "        #将结果变为概率\n",
    "        self.Sigmoid = nn.Sigmoid()        \n",
    "\n",
    "    def construct(self, x):        \n",
    "        return self.Sigmoid(self.fc(x)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43de3811",
   "metadata": {},
   "source": [
    "### 5.3 自定义Focal Loss损失函数"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "466c2b3d",
   "metadata": {},
   "source": [
    "首先定义损失函数，再自定义Focal Loss损失函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e4f60f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义损失函数\n",
    "class FocalLossForLabel(nn.LossBase):\n",
    "    def __init__(self,alpha=0.25, gamma=2.0, reduction=\"mean\"):\n",
    "        super(FocalLossForLabel, self).__init__(reduction)\n",
    "        self.abs = ops.abs\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "\n",
    "    def construct(self, base, target):\n",
    "        at = self.alpha*target + (1-self.alpha)*(1-target)\n",
    "        pt = base*target + (1-base)*(1-target)\n",
    "        loss = -at*(1-pt)**self.gamma * ops.log(pt)\n",
    "        return loss\n",
    "\n",
    "# 自定义Focal Loss损失函数\n",
    "class FocalLoss(nn.Cell):\n",
    "    def __init__(self, backbone, loss_fn):\n",
    "        super(FocalLoss, self).__init__(auto_prefix=False)\n",
    "        self._backbone = backbone\n",
    "        self._loss_fn = loss_fn\n",
    "        \n",
    "    def construct(self, data, label):\n",
    "        output = self._backbone(data)\n",
    "        return self._loss_fn(output, label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5981e67",
   "metadata": {},
   "source": [
    "## 6、模型训练"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40df9c56",
   "metadata": {},
   "source": [
    "完成数据预处理、网络定义、损失函数之后，选择优化器，开始模型训练。模型训练包含10层迭代，数据集按分组从训练集中抽取数据，输入网络计算得到损失函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b8bc9c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "ds_train = create_dataset(num_data=10000)\n",
    "net = LinearNet()\n",
    "# 定义损失函数\n",
    "loss_fnn = FocalLossForLabel() \n",
    "# 定义损失网络，连接前向网络和损失函数\n",
    "# loss_net = FocalLoss(net, loss)\n",
    "# 定义优化器\n",
    "opt = nn.Momentum(net.trainable_params(), learning_rate=0.005, momentum=0.9)\n",
    "\n",
    "# 1. Define forward function\n",
    "def forward_fn(data, label):\n",
    "    logits = net(data)\n",
    "    loss = loss_fnn(logits, label)\n",
    "    return loss, logits\n",
    "\n",
    "# 2. Get gradient function\n",
    "grad_fn = ms.value_and_grad(forward_fn, None, opt.parameters, has_aux=True)\n",
    "\n",
    "# 3. Define function of one-step training\n",
    "def train_step(data, label):\n",
    "    (loss, _), grads = grad_fn(data, label)\n",
    "    opt(grads)\n",
    "    return loss\n",
    "\n",
    "def train(model, dataset):\n",
    "    size = dataset.get_dataset_size()\n",
    "    model.set_train()\n",
    "    for batch, (data, label) in enumerate(dataset.create_tuple_iterator()):\n",
    "        # print(label)\n",
    "        loss = train_step(data, label)\n",
    "        # print(loss.shape)\n",
    "\n",
    "        if batch % 10 == 0:\n",
    "            loss, current = loss.asnumpy(), batch\n",
    "            # print(f\"loss: {loss:>7f}  [{current:>3d}/{size:>3d}]\")\n",
    "epochs = 10\n",
    "for t in range(epochs):\n",
    "    # print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(net, ds_train)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "184076a3-c32a-4d4e-be7f-cf9a731e597b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[Tensor(shape=[], dtype=Float32, value= 2.61318)]]\n",
      "[Tensor(shape=[], dtype=Float32, value= 3.47061)]\n"
     ]
    }
   ],
   "source": [
    "#输出参数值\n",
    "for i in net.trainable_params():\n",
    "    print(np.array(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a62c399",
   "metadata": {},
   "source": [
    "## 7、模型预测"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "492488fa",
   "metadata": {},
   "source": [
    "首先随机生成测试数据，再定义标签，然后进行模型测试，最后输出模型的预测结果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5f49645d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data:[[-1]]\n",
      "predict result:[[[0.70212436]]]\n",
      "true result:1\n"
     ]
    }
   ],
   "source": [
    "from mindspore import Tensor\n",
    "\n",
    "# 生成测试数据\n",
    "w=2.0\n",
    "b=3.0\n",
    "\n",
    "x = np.array(-1).reshape(1,1)\n",
    "x1 = np.array([x]).astype(np.float32)\n",
    "    \n",
    "true_result = 1 if x * w + b >0 else 0\n",
    "print('data:' + '%s'%x)\n",
    "# 模型测试\n",
    "test_result = net(Tensor(x1))\n",
    "\n",
    "print('predict result:' + '%s'%test_result)\n",
    "print('true result:' + '%s'%true_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6d60ad-8a1d-4eae-bd16-00ddf2961b0e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
