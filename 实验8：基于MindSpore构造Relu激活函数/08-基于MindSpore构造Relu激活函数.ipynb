{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. 基于MindSpore构造激活函数\n",
    "本实验主要介绍使用MindSpore实现神经网络中的ReLU激活函数，使用自定义数据进行测试。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 实验目的\n",
    "- 了解激活函数在人工神经网络中的作用。\n",
    "- 掌握如何使用MindSpore构造ReLU激活函数，并使用自定义数据进行测试。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. ReLU激活函数知识点介绍\n",
    "激活函数是在人工神经网络的神经元上运行的函数，负责将神经元的输入映射到输出端。  \n",
    "激活函数对于神经网络模型去学习、理解复杂和非线性的函数具有十分重要的意义，它们将非线性特性引入到网络中。如图所示，在神经元中，输入（inputs）通过加权、求和后，还被作用在一个函数上，这个函数就是激活函数。  \n",
    "![](Figures/fig_001.png)  \n",
    "如果不使用激活函数，神经网络中每一层的输入都是上一层输出的线性函数，无论神经网络有多少层，输出都是输入的线性组合，这种情况网络会退化为最原始的感知机。使用非线性激活函数是为了增加神经网络模型的非线性因素，使网络更加强大，可以学习更加复杂的事物。  \n",
    "整流线性单元（Rectified linear unit, ReLU）是现代神经网络中最常用的激活函数，是大多数前馈神经网络默认使用的激活函数，函数表达式如下：   \n",
    "$$\n",
    "f(x) =\\max(0,x)\n",
    "$$  \n",
    "函数图像：  \n",
    "![](Figures/fig_002.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 实验环境\n",
    "在动手进行实践之前，需要注意以下几点：\n",
    "* 确保实验环境正确安装，包括安装MindSpore。安装过程：首先登录[MindSpore官网安装页面](https://www.mindspore.cn/install)，根据安装指南下载安装包及查询相关文档。同时，官网环境安装也可以按下表说明找到对应环境搭建文档链接，根据环境搭建手册配置对应的实验环境。\n",
    "* 推荐使用交互式的计算环境Jupyter Notebook，其交互性强，易于可视化，适合频繁修改的数据分析实验环境。\n",
    "* 实验也可以在华为云一站式的AI开发平台ModelArts上完成。\n",
    "* 推荐实验环境：MindSpore版本=2.4；Python环境=3.9。\n",
    "\n",
    "\n",
    "|  硬件平台 |  操作系统  | 软件环境 | 开发环境 | 环境搭建链接 |\n",
    "| :-----:| :----: | :----: |:----:   |:----:   |\n",
    "| CPU | Windows-x64 | MindSpore2.4 Python3.9 | JupyterNotebook |[MindSpore环境搭建实验手册第二章2.1节和第三章3.1节](./MindSpore环境搭建实验手册.docx)|\n",
    "| GPU CUDA 10.1|Linux-x86_64| MindSpore2.4 Python3.9 | JupyterNotebook |[MindSpore环境搭建实验手册第二章2.2节和第三章3.1节](./MindSpore环境搭建实验手册.docx)|\n",
    "| Ascend 910  | Linux-x86_64| MindSpore2.4 Python3.9 | JupyterNotebook |[MindSpore环境搭建实验手册第四章](./MindSpore环境搭建实验手册.docx)|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. 数据处理\n",
    "## 4.1 数据准备\n",
    "自定义张量（Tensor）数据进行测试。  \n",
    "Tensor本质上是一个多维数组（multidimensional array），使用  Tensor的目的是能够创造更高维度的矩阵、向量。  \n",
    "本实验中定义的张量数据 Tensor 格式如下所示：\n",
    "$$\n",
    "[<Array_1>,<Array_2>,\\cdots, <Array_n>]\n",
    "$$  \n",
    "测试数据定义为： \n",
    "  \n",
    "`[[ 1.0,  2.0, -4.0,  1.3], [-1.3,  2.0,  1.0, -6.0]]`\n",
    "## 4.2 数据加载\n",
    "代码："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 引入mindspore\n",
    "import mindspore as ms\n",
    "# 引入神经网络模块\n",
    "from mindspore.nn import Cell\n",
    "# 引入MindSpore的ReLU函数接口\n",
    "from mindspore.nn import ReLU\n",
    "from mindspore import dtype as mstype\n",
    "# 定义张量数据\n",
    "tensor = ms.Tensor([[ 1.0,  2.0, -4.0,  1.3],\n",
    "                    [-1.3,  2.0,  1.0, -6.0]], dtype=mstype.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. 模型构建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 继承Cell类，构造ReLU函数\n",
    "class My_Relu(Cell):\n",
    "    def __init__(self):\n",
    "        super(My_Relu, self).__init__()\n",
    "    def construct(self, x):        \n",
    "        x[x<0] = 0.0  # 换表达方式:用if else改写relu实现      \n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. 模型测试\n",
    "使用自定义数据对ReLU函数进行测试，观察函数实现是否正确。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "自定义ReLU函数\n",
      " [[1.  2.  0.  1.3]\n",
      " [0.  2.  1.  0. ]]\n",
      "接口ReLU函数\n",
      " [[1.  2.  0.  1.3]\n",
      " [0.  2.  1.  0. ]]\n"
     ]
    }
   ],
   "source": [
    "# 实例化ReLU函数\n",
    "my_relu = My_Relu()\n",
    "# 输出\n",
    "output = my_relu(tensor)\n",
    "# 打印输出\n",
    "relu = ReLU()\n",
    "output_2 = relu(tensor)\n",
    "print('自定义ReLU函数\\n', output)\n",
    "print('接口ReLU函数\\n', output_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 基于MindSpore构造常见激活函数(附)\n",
    "\n",
    "在Python中，我们可以使用NumPy库来构建常见的激活函数。NumPy是一个强大的科学计算模块，它包含了很多的数学函数，可以用来快速方便地进行各种数学运算。\n",
    "\n",
    "以下是一些常见的激活函数以及它们的Python实现：\n",
    "\n",
    "**1、线性函数（Linear Function）：**\n",
    "\n",
    "这是一个线性的函数，它的输出和输入是线性关系。在MindS'pore中，我们可以直接使用数组操作来实现这个函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mindspore as ms\n",
    " \n",
    "def linear(x):\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2、双曲线正切激活函数（Tanh）：**\n",
    "\n",
    "双曲线正切函数在MindSpore中可以通过ops.tanh函数来实现。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7615942 0.9640276 0.9950557 0.9993442 1.0000098]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import mindspore\n",
    "from mindspore import Tensor, ops\n",
    " \n",
    "def tanh(x):\n",
    "    return ops.tanh(x)\n",
    "\n",
    "input = Tensor(np.array([1, 2, 3, 4, 5]), mindspore.float32)\n",
    "output = tanh(input)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3、反正切激活函数（Arctan）：**\n",
    "\n",
    "反正切函数在MindSpore中可以通过ops.arctan函数来实现。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7853982 0.       ]\n"
     ]
    }
   ],
   "source": [
    "import mindspore\n",
    "from mindspore import Tensor, ops\n",
    "import numpy as np\n",
    " \n",
    "def arctan(x):\n",
    "    return ops.arctan(x)\n",
    "\n",
    "x = Tensor(np.array([1.0, 0.0]), mindspore.float32)\n",
    "output = arctan(x)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4、自然指数激活函数（Exp）：**\n",
    "\n",
    "自然指数函数在MindSpore中可以通过ops.exp函数来实现。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.         2.7182798 20.085548 ]\n"
     ]
    }
   ],
   "source": [
    "import mindspore\n",
    "import numpy as np\n",
    "from mindspore import Tensor, ops\n",
    " \n",
    "def exp(x):\n",
    "    return ops.exp(x)\n",
    "\n",
    "input = Tensor(np.array([0.0, 1.0, 3.0]), mindspore.float32)\n",
    "output = exp(input)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5、sigmoid激活函数：**\n",
    "\n",
    "Sigmoid函数在MindSpore中可以通过1 / (1 + ops.exp(-x))来实现。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5        0.7310589  0.95257413]\n"
     ]
    }
   ],
   "source": [
    "import mindspore\n",
    "import numpy as np\n",
    "from mindspore import Tensor, ops\n",
    " \n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + ops.exp(-x))\n",
    "\n",
    "input = Tensor(np.array([0.0, 1.0, 3.0]), mindspore.float32)\n",
    "output = sigmoid(input)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6、ReLU激活函数：**\n",
    "\n",
    "ReLU（Rectified Linear Unit）函数在MindSpore中可以通过ops.maximum(x, 0)来实现。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4. 5. 6.]\n"
     ]
    }
   ],
   "source": [
    "import mindspore\n",
    "import numpy as np\n",
    "from mindspore import Tensor, ops\n",
    "\n",
    "def relu(x, other):\n",
    "    return ops.maximum(x, other)\n",
    "\n",
    "input = Tensor(np.array([1.0, 5.0, 3.0]), mindspore.float32)\n",
    "other = Tensor(np.array([4.0, 2.0, 6.0]), mindspore.float32)\n",
    "output = relu(input, other)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7、Leaky ReLU激活函数：**\n",
    "\n",
    "Leaky ReLU是ReLU的一个变体，它在输入是负数的时候不是直接置零，而是给予一个小的斜率。在MindSpore中，我们可以通过条件语句来实现这个函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.1  2.   5.   3. ]\n"
     ]
    }
   ],
   "source": [
    "import mindspore\n",
    "import numpy as np\n",
    "from mindspore import Tensor, ops\n",
    " \n",
    "def leaky_relu(x, alpha=0.1):\n",
    "    return ops.maximum(x, alpha*x)\n",
    "\n",
    "inputs = Tensor(np.array([-1.0, 2.0, 5.0, 3.0]), mindspore.float32)\n",
    "output = leaky_relu(inputs)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**8、Softmax激活函数：**\n",
    "\n",
    "Softmax函数通常用于分类问题，它可以将输入向量归一化，使得所有的输出值在0和1之间，且和为1。在MindSpore中，我们可以通过如下方式来实现这个函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.04201005 0.11419506 0.8437948 ]\n"
     ]
    }
   ],
   "source": [
    "import mindspore\n",
    "import numpy as np\n",
    "from mindspore import Tensor, ops\n",
    " \n",
    "def softmax(x):\n",
    "    exp_x = ops.exp(x)\n",
    "    return exp_x / ops.sum(exp_x, dim=-1, keepdim=True)\n",
    "\n",
    "input = Tensor(np.array([0.0, 1.0, 3.0]), mindspore.float32)\n",
    "output = softmax(input)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "vscode": {
   "interpreter": {
    "hash": "e4ab65fdc43de4932de46c69418c64f6e3769852db39afdc53804a8e5b8ff4a1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
