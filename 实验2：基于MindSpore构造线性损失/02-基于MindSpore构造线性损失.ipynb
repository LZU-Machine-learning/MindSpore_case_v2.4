{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d5d45b8",
   "metadata": {},
   "source": [
    "# 2. 基于MindSpore构造线性回归的损失函数---MSE（均方误差）损失函数"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bc5f935",
   "metadata": {},
   "source": [
    "本小节主要介绍构造线性回归的损失函数的设计，使用MSE（均方误差）损失函数作为讲解实例,并使用自定义数据进行测试。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b80aac32",
   "metadata": {},
   "source": [
    "## 1、实验目的\n",
    "- 理解MSE（均方误差）损失函数的意义。\n",
    "- 自定义损失函数MSEloss。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a844a50b",
   "metadata": {},
   "source": [
    "## 2、MSE（均方误差）损失函数原理介绍\n",
    "MSE用于计算预测值与标签值之间的均方误差。公式如下：\n",
    "$$\n",
    "MSE =\\frac1{n}\\sum_{i=1}^n({\\hat{y}_i - y_i})^2\n",
    "$$\n",
    "\n",
    "$\\hat{y}_i$为预测值，$y_i$为标签值，$n$为样本的数量。\n",
    "MSE范围为 $[0,+∞)$，当预测值与真实值完全相同时为0，误差越大，该值越大。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad6563ed",
   "metadata": {},
   "source": [
    "## 3、实验环境\n",
    "在动手进行实践之前，需要注意以下几点：\n",
    "* 确保实验环境正确安装，包括安装MindSpore。安装过程：首先登录[MindSpore官网安装页面](https://www.mindspore.cn/install)，根据安装指南下载安装包及查询相关文档。同时，官网环境安装也可以按下表说明找到对应环境搭建文档链接，根据环境搭建手册配置对应的实验环境。\n",
    "* 推荐使用交互式的计算环境Jupyter Notebook，其交互性强，易于可视化，适合频繁修改的数据分析实验环境。\n",
    "* 实验也可以在华为云一站式的AI开发平台ModelArts上完成。\n",
    "* 推荐实验环境：MindSpore版本=MindSpore 2.4；Python环境=3.11。\n",
    "\n",
    "\n",
    "|  硬件平台 |  操作系统  | 软件环境 | 开发环境 | 环境搭建链接 |\n",
    "| :-----:| :----: | :----: |:----:   |:----:   |\n",
    "| CPU | Windows-x64 | MindSpore2.4 Python3.11 | JupyterNotebook |[MindSpore环境搭建实验手册第二章2.1节和第三章3.1节](./MindSpore环境搭建实验手册.docx)|\n",
    "| GPU CUDA 10.1|Linux-x86_64| MindSpore2.4 Python3.11 | JupyterNotebook |[MindSpore环境搭建实验手册第二章2.2节和第三章3.1节](./MindSpore环境搭建实验手册.docx)|\n",
    "| Ascend 910  | Linux-x86_64| MindSpore2.4 Python3.11 | JupyterNotebook |[MindSpore环境搭建实验手册第四章](./MindSpore环境搭建实验手册.docx)|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ff6c95",
   "metadata": {},
   "source": [
    "## 4、数据处理"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e85a0411",
   "metadata": {},
   "source": [
    "### 4.1 数据准备\n",
    "\n",
    "本实验实验使用根据公式$$z=a x^{2}+b y^{3} + c + noise$$\n",
    "生成并添加噪声的数据，$a$,$b$,$c$为系数默认值分别为2,3,5；$noise$为噪声由均值为0方差为0.03的正态分布随机生成；$z$为标签值。数据形式为：$([x^{2},y^{3}],z)$，因为$x$,$y$,$noise$均需随机生成故此处不在展示数据。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb9b9030",
   "metadata": {},
   "source": [
    "### 4.2 数据加载\n",
    "这里进行自定义数据集的生成和增强操作，首先`get_data`函数根据公式获取数据，然后在`create_dataset`函数生成数据集，并进行数据增强和处理操作：\n",
    "- 定义进行数据增强和处理所需要的一些参数。\n",
    "- 根据参数，生成对应的数据增强操作。\n",
    "- 对生成的数据集进行处理。\n",
    "- 对处理好的数据进行样例展示。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78b7ef62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from mindspore import dataset as ds\n",
    "\n",
    "# 获取数据 num要生成的点数\n",
    "def get_data(num, a=2.0, b=3.0, c=5.0):\n",
    "    \n",
    "    for _ in range(num):\n",
    "        # 均匀分布\n",
    "        x = np.random.uniform(-1.0, 1.0)\n",
    "        y = np.random.uniform(-1.0, 1.0)\n",
    "        # 添加噪声\n",
    "        noise = np.random.normal(0, 0.03)\n",
    "        z = a * x ** 2 + b * y ** 3 + c + noise\n",
    "        yield np.array([[x**2], [y**3]],dtype=np.float32).reshape(1,2), np.array([z]).astype(np.float32)\n",
    "\n",
    "# 生成数据集并增强\n",
    "def create_dataset(num_data, batch_size=16, repeat_size=1):\n",
    "    # 生成数据集\n",
    "    input_data = ds.GeneratorDataset(list(get_data(num_data)), column_names=['xy','z'])\n",
    "    # 划分批次\n",
    "    input_data = input_data.batch(batch_size)\n",
    "    # 增强数据集\n",
    "    input_data = input_data.repeat(repeat_size)\n",
    "    return input_data\n",
    " \n",
    "data_number = 160       # 数据集大小\n",
    "batch_number = 10       # 批量大小  \n",
    "repeat_number = 10      # 增强次数\n",
    "\n",
    "# 训练集\n",
    "ds_train = create_dataset(data_number, batch_size=batch_number, repeat_size=repeat_number)\n",
    "# 测试集\n",
    "ds_test = create_dataset(data_number, batch_size=batch_number, repeat_size=repeat_number)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e17d31ae",
   "metadata": {},
   "source": [
    "## 5、模型构建\n",
    "\n",
    "模型的构建包括如下部分：\n",
    "- 导入库和函数\n",
    "- 定义线性模型\n",
    "- 自定义损失函数MSEloss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3fee99d",
   "metadata": {},
   "source": [
    "### 5.1 导入所需库和函数并配置运行信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ccccf412",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 时间处理模块\n",
    "import time\n",
    "# 科学计算库\n",
    "import numpy as np\n",
    "# MindSpore库\n",
    "import mindspore as ms\n",
    "# 常见算子操作\n",
    "import mindspore.ops as ops\n",
    "# 数据集处理模块\n",
    "from mindspore import dataset as ds\n",
    "# 环境设置模块，神经网络模块，张量，模型编译\n",
    "from mindspore import nn, Tensor, Model\n",
    "# MindSpore环境设置的0号种子\n",
    "ms.common.set_seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53203b62",
   "metadata": {},
   "source": [
    "### 5.2 定义线性模型\n",
    "\n",
    "为了使用定义的损失函数（下一小节定义），通过基础nn.Cell类，构建了一个简单的线性模型，该模型只有一层全连接层（2输入节点，1输入），且只有前向传播。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3be4e656",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义线性模型\n",
    "class LinearNet(nn.Cell):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(LinearNet, self).__init__()\n",
    "        # 全连接层\n",
    "        self.fc = nn.Dense(2, 1, 0.02, 0.02)\n",
    " \n",
    "    def construct(self, x):\n",
    "        # 前向传播\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "791d00b5",
   "metadata": {},
   "source": [
    "查看模型中参数维度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82f5843e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Param Shape is: 2\n",
      "Parameter (name=fc.weight, shape=(1, 2), dtype=Float32, requires_grad=True) [[0.02 0.02]]\n",
      "Parameter (name=fc.bias, shape=(1,), dtype=Float32, requires_grad=True) [0.02]\n"
     ]
    }
   ],
   "source": [
    "net = LinearNet()\n",
    "model_params = net.trainable_params()\n",
    "\n",
    "# 显示模型的参数及其大小\n",
    "print ('Param Shape is: {}'.format(len(model_params)))\n",
    "for net_param in net.trainable_params():\n",
    "    print(net_param, net_param.asnumpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9726e43",
   "metadata": {},
   "source": [
    "### 5.3 自定义损失函数MSEloss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cbba5996-75c9-4b91-80c2-6b63f9e3d6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse_loss(y_true, y_pred):\n",
    "\n",
    "\t#计算真实值和预测值之间的差异\n",
    "\tdiff=y_true-y_pred\n",
    "\t\n",
    "\t#计算差值的平方\n",
    "\tsq_diff=ops.square(diff)\n",
    "\t\n",
    "\t#计算均方误差，即平方差的平均值\n",
    "\t#使用ops.mean计算平均值\n",
    "\tloss=ops.mean(sq_diff)\n",
    "\t\n",
    "\treturn loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c1efe8",
   "metadata": {},
   "source": [
    "## 6、模型训练\n",
    "\n",
    "完成数据预处理、网络定义、损失函数之后，选择优化器，开始模型训练。模型训练包含1层迭代，数据集按分组从训练集中抽取数据，输入网络计算得到损失。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84b01ede",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 35.231720  [  0/160]\n",
      "loss: 24.797668  [ 10/160]\n",
      "loss: 26.070568  [ 20/160]\n",
      "loss: 22.846748  [ 30/160]\n",
      "loss: 22.254169  [ 40/160]\n",
      "loss: 24.888565  [ 50/160]\n",
      "loss: 27.226030  [ 60/160]\n",
      "loss: 14.459282  [ 70/160]\n",
      "loss: 13.477544  [ 80/160]\n",
      "loss: 15.125378  [ 90/160]\n",
      "loss: 14.983068  [100/160]\n",
      "loss: 12.220332  [110/160]\n",
      "loss: 16.856186  [120/160]\n",
      "loss: 7.975780  [130/160]\n",
      "loss: 7.980481  [140/160]\n",
      "loss: 7.536829  [150/160]\n",
      "Avg loss: 6.511009 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# 选择动量优化器\n",
    "optim = nn.Momentum(net.trainable_params(), learning_rate=0.001, momentum=0.6)\n",
    "\n",
    "# 1. Define forward function\n",
    "def forward_fn(data, label):\n",
    "    logits = net(data)\n",
    "    loss = mse_loss(logits, label)\n",
    "    return loss, logits\n",
    "\n",
    "# 2. Get gradient function\n",
    "grad_fn = ms.value_and_grad(forward_fn, None, optim.parameters, has_aux=True)\n",
    "\n",
    "# 3. Define function of one-step training\n",
    "def train_step(data, label):\n",
    "    (loss, _), grads = grad_fn(data, label)\n",
    "    optim(grads)\n",
    "    return loss\n",
    "\n",
    "def train(model, dataset):\n",
    "    size = dataset.get_dataset_size()\n",
    "    model.set_train()\n",
    "    for batch, (data, label) in enumerate(dataset.create_tuple_iterator()):\n",
    "        # print(label)\n",
    "        loss = train_step(data, label)\n",
    "        # print(loss)\n",
    "\n",
    "        if batch % 10 == 0:\n",
    "            loss, current = loss.asnumpy(), batch\n",
    "            print(f\"loss: {loss:>7f}  [{current:>3d}/{size:>3d}]\")\n",
    "\n",
    "\n",
    "def test(model, dataset, loss_fn):\n",
    "    num_batches = dataset.get_dataset_size()\n",
    "    model.set_train(False)\n",
    "    total, test_loss, correct = 0, 0, 0\n",
    "    for data, label in dataset.create_tuple_iterator():\n",
    "        pred = model(data)\n",
    "        total += len(data)\n",
    "        test_loss += loss_fn(pred, label).asnumpy()\n",
    "    test_loss /= num_batches\n",
    "    correct /= total\n",
    "    print(f\"Avg loss: {test_loss:>8f} \\n\")\n",
    "\n",
    "epochs = 1\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(net, ds_train)\n",
    "    test(net, ds_test, mse_loss)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b7f33c1",
   "metadata": {},
   "source": [
    "## 7、模型预测\n",
    "\n",
    "模型训练完成后，输入测试集进行模型预测，计算平方损失函数值。模型预测时不需要设置优化器，只需要设置网络、损失函数和评估指标。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d7cfb876-2a9d-4fe2-bda7-cc3ba938f6d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg loss: 6.511009\n"
     ]
    }
   ],
   "source": [
    "net.set_train(False)\n",
    "total_num = len(ds_test)\n",
    "total_loss = 0\n",
    "for data, label in ds_test:\n",
    "    pred = net(data)\n",
    "    pred_loss = mse_loss(pred, label).asnumpy()\n",
    "    total_loss += pred_loss\n",
    "print(f\"Avg loss: {total_loss/total_num:>8f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c12008a-9ae9-43d3-86c2-0e70a849e3bb",
   "metadata": {},
   "source": [
    "# 基于MindSpore构造线性回归的损失函数(方法二)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c281ca5-3120-4bb2-b33b-9e700055c2b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 1)\n",
      "(3, 3)\n",
      "(3, 1)\n",
      "116.666664\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import mindspore as ms\n",
    "from mindspore import ops\n",
    " \n",
    "def linear_loss_naive(w, X, y):\n",
    "    \"\"\"\n",
    "    基于MindSpore.ops的简单线性回归损失函数实现。\n",
    "    \n",
    "    参数:\n",
    "    w -- 权重，一个向量\n",
    "    X -- 数据集，一个矩阵\n",
    "    y -- 标签，一个向量\n",
    "    \n",
    "    返回:\n",
    "    损失 -- 损失值，一个标量\n",
    "    \"\"\"\n",
    "    # 预测值\n",
    "    y_pred = ops.dot(X, w)\n",
    "    # 平方损失\n",
    "    loss = (y_pred - y) ** 2\n",
    "    # 平均损失\n",
    "    loss = ops.sum(loss) / len(y)\n",
    "    return loss\n",
    " \n",
    "# 示例使用\n",
    "# 假设 w_true, X, y 已经被定义\n",
    "w_true = ms.Tensor([1, -3, 2], ms.float32).reshape((3, 1))\n",
    "print(w_true.shape)\n",
    "X = ms.Tensor([[1, 1, 1], [2, 2, 2], [3, 3, 3]], ms.float32)\n",
    "print(X.shape)\n",
    "y = ms.Tensor([5, 10, 15], ms.float32).reshape((3, 1))\n",
    "print(y.shape)\n",
    "# 计算损失\n",
    "loss = linear_loss_naive(w_true, X, y)\n",
    "print(loss)  # 输出损失值"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
